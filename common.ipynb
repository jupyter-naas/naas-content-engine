{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "633951dc-ca87-4032-ad2d-b76a909861bf",
   "metadata": {},
   "source": [
    "# Common functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac586014-0e55-4799-89d5-8c9418949b85",
   "metadata": {},
   "source": [
    "By default, **your databases** will be stored in Naas in the **\"Inputs\"** folder of each tool.<br>\n",
    "You can edit it by changing the path of the outputs below if you want to connect to any kind of other tools.\n",
    "\n",
    "*LinkedIn:*\n",
    "- Profile posts stats\n",
    "- Company posts stats\n",
    "- Profile connections\n",
    "- Company followers\n",
    "- Profile posts engagements\n",
    "- Company posts engagements\n",
    "\n",
    "*YouTube:*\n",
    "- Video stats\n",
    "\n",
    "By default, all **your assets** will be store in Naas in the **\"Outputs\"**:\n",
    "- Image\n",
    "- HTML\n",
    "- Post process data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d5465-bce2-42f3-8d18-6f821dae07a5",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d3ac41-a2af-4540-b6f4-c2a5be24714d",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a0ba26-31f8-4097-bf19-852a39cfdf9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import naas\n",
    "import pandas as pd\n",
    "from naas_drivers import notion, linkedin, youtube\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pytz\n",
    "from os import path, environ, makedirs\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from naas_drivers.tools.notion import Link, BlockEmbed\n",
    "import plotly.express as px\n",
    "from dateutil import tz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68da7dd9-dc09-413c-9afc-2bf5c22c6f9c",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be59b74-b055-4ff4-b422-2e23abd16584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(file_path, storage=\"Naas\"):\n",
    "    try:\n",
    "        # Get CSV in Naas\n",
    "        if storage == \"Naas\":\n",
    "            if not naas.is_production():\n",
    "                try:\n",
    "                    input_path = path.join(PROD_DIR, file_path)\n",
    "                    df = pd.read_csv(input_path) \n",
    "                except:\n",
    "                    input_path = path.join(DEV_DIR, file_path)\n",
    "                    df = pd.read_csv(input_path)\n",
    "                    return df\n",
    "            else:\n",
    "                input_path = path.join(PROD_DIR, file_path)\n",
    "                df = pd.read_csv(input_path) \n",
    "        # Get AWS \n",
    "        elif storage == \"AWS\":\n",
    "            df = wr.s3.read_parquet(file_path, dataset=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        # Empty dataframe returned\n",
    "        return pd.DataFrame()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44e10e3-12c2-43a5-ac37-000109452266",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T16:30:04.247951Z",
     "iopub.status.busy": "2022-02-05T16:30:04.247695Z",
     "iopub.status.idle": "2022-02-05T16:30:04.250751Z",
     "shell.execute_reply": "2022-02-05T16:30:04.250118Z",
     "shell.execute_reply.started": "2022-02-05T16:30:04.247927Z"
    },
    "tags": []
   },
   "source": [
    "### Setup Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64046878-20ff-4a4f-ae34-af3773fc43fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Timezone\n",
    "TIMEZONE = naas.secret.get(\"TIMEZONE\")\n",
    "\n",
    "# Month Rolling\n",
    "MONTH_ROLLING = 12\n",
    "\n",
    "# MTD\n",
    "PERIOD_MTD = \"%Y-%m\"\n",
    "ORDER_MTD = \"%Y%m\"\n",
    "DISPLAY_MTD = \"%b %Y\"\n",
    "TEXT_MTD = \"This month\"\n",
    "TEXT2_MTD = \"months\"\n",
    "SCENARIO_MTD = \"MTD\"\n",
    "CURRENT_MTD = datetime.now().strftime(PERIOD_MTD)\n",
    "\n",
    "# Datetime format\n",
    "DATE_FORMAT = \"%Y-%m-%d\"\n",
    "DATETIME_FORMAT = \"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "# Naas directory\n",
    "PROJECT = naas.secret.get(\"GIT_REPO_NAME\")\n",
    "PROJECT_PATH = naas.secret.get(\"GIT_REPO_PATH\")\n",
    "\n",
    "# Manage DIR\n",
    "PROD_DIR = path.join(\"/\", \"home\", \"ftp\", \"âš¡ â†’ Production\", PROJECT)\n",
    "DEV_DIR = PROJECT_PATH\n",
    "if naas.is_production():\n",
    "    DIR = PROD_DIR\n",
    "else:\n",
    "    DIR = DEV_DIR\n",
    "    \n",
    "# Naas Assets file\n",
    "ASSETS = \"Naas_Assets.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fbe5a6-310d-40d2-9450-635ce4ee528f",
   "metadata": {},
   "source": [
    "### Setup Notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36693de8-cc96-455f-ae3e-f3a9354af4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTION_CONTENT_DB = naas.secret.get(\"NOTION_CONTENT_DB\")\n",
    "NOTION_TOKEN = naas.secret.get(\"NOTION_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34071b7-4b95-4034-84a2-3e3deec9f1d2",
   "metadata": {},
   "source": [
    "### Setup LinkedIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e78f7d-7165-4024-9013-b6e86e6b4de4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LinkedIn cookies\n",
    "LI_AT = naas.secret.get(\"LI_AT\") # EXAMPLE : \"AQFAzQN_PLPR4wAAAXc-FCKmgiMit5FLdY1af3-2\"\n",
    "JSESSIONID = naas.secret.get(\"JSESSIONID\") # EXAMPLE : \"ajax:8379907400220387585\"\n",
    "LINKEDIN_PROFILE_URL = naas.secret.get(\"LINKEDIN_PROFILE_URL\") # EXAMPLE : \"ajax:8379907400220387585\"\n",
    "LINKEDIN_COMPANY_URL = naas.secret.get(\"LINKEDIN_COMPANY_URL\") # EXAMPLE : \"ajax:8379907400220387585\"\n",
    "\n",
    "# Outputs folders\n",
    "LINKEDIN_INPUTS = path.join(\"LinkedIn\", \"Inputs\")\n",
    "if not path.exists(path.join(DIR, LINKEDIN_INPUTS)):\n",
    "    makedirs(path.join(DIR, LINKEDIN_INPUTS))\n",
    "\n",
    "LINKEDIN_OUTPUTS = path.join(\"LinkedIn\", \"Outputs\")\n",
    "if not path.exists(path.join(DIR, LINKEDIN_OUTPUTS)):\n",
    "    makedirs(path.join(DIR, LINKEDIN_OUTPUTS))\n",
    "\n",
    "# Get LinkedIn ID\n",
    "def get_identity(file_path, identity):\n",
    "    df = pd.DataFrame()\n",
    "    file_path = path.join(DIR, file_path)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except FileNotFoundError as e:\n",
    "        # Empty dataframe returned\n",
    "        if identity == \"profile\":\n",
    "            if naas.secret.get(\"LINKEDIN_PROFILE_URL\"):\n",
    "                df = linkedin.connect(LI_AT, JSESSIONID).profile.get_identity(LINKEDIN_PROFILE_URL)\n",
    "        elif identity == \"company\":\n",
    "            if naas.secret.get(\"LINKEDIN_COMPANY_URL\"):\n",
    "                df = linkedin.connect(LI_AT, JSESSIONID).company.get_info(LINKEDIN_COMPANY_URL)\n",
    "        if len(df) > 0:\n",
    "            df.to_csv(file_path, index=False)\n",
    "            naas.dependency.add(file_path)\n",
    "            return df\n",
    "    return df\n",
    "\n",
    "# LinkedIn Profile info\n",
    "LK_PROFILE_IDENTITY = path.join(LINKEDIN_INPUTS, \"LINKEDIN_PROFILE.csv\")\n",
    "df_profile = get_identity(file_path=LK_PROFILE_IDENTITY, identity=\"profile\")\n",
    "LK_PROFILE_ID = \"\"\n",
    "LK_FULLNAME = \"\"\n",
    "if len(df_profile) > 0:\n",
    "    LK_PROFILE_ID = df_profile.loc[0, \"PROFILE_ID\"]\n",
    "    LK_FIRSTNAME = df_profile.loc[0, \"FIRSTNAME\"]\n",
    "    LK_LASTNAME = df_profile.loc[0, \"LASTNAME\"]\n",
    "    LK_FULLNAME = f\"{LK_FIRSTNAME} {LK_LASTNAME}\"\n",
    "    LK_PROFILE_CHECK = True\n",
    "\n",
    "# LinkedIn Company info\n",
    "LK_COMPANY_INFO = path.join(LINKEDIN_INPUTS, \"LINKEDIN_COMPANY.csv\")\n",
    "df_company = get_identity(file_path=LK_COMPANY_INFO, identity=\"company\")\n",
    "LK_COMPANY_ID = \"\"\n",
    "LK_COMPANY_NAME = \"\"\n",
    "if len(df_company) > 0:\n",
    "    LK_COMPANY_ID = df_company.loc[0, \"COMPANY_ID\"]\n",
    "    LK_COMPANY_NAME = df_company.loc[0, \"COMPANY_NAME\"]\n",
    "    LK_COMPANY_CHECK = True\n",
    "    \n",
    "# Posts update\n",
    "LINKEDIN_POSTS_UPDATE = 7\n",
    "LINKEDIN_MIN_UPDATED_TIME = 300\n",
    "NO_TOP_FANS = 20\n",
    "\n",
    "# Linkedin Stype\n",
    "LINKEDIN = \"LinkedIn\"\n",
    "LINKEDIN_LOGO = \"https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/LinkedIn_logo_initials.png/800px-LinkedIn_logo_initials.png\"\n",
    "LINKEDIN_COLOR = \"#1293d2\"\n",
    "LINKEDIN_COLOR2 = \"#cfe9f6\"\n",
    "\n",
    "# LinkedIn Profile DATABASES\n",
    "LK_PROFILE_POSTS = path.join(LINKEDIN_INPUTS, f'LINKEDIN_PROFILE_POSTS_{LK_PROFILE_ID}.csv')\n",
    "LK_PROFILE_CONNECTIONS = path.join(LINKEDIN_INPUTS, f'LINKEDIN_PROFILE_CONNECTIONS_{LK_PROFILE_ID}.csv')\n",
    "LK_PROFILE_POSTS_LIKES = path.join(LINKEDIN_INPUTS, f'LINKEDIN_PROFILE_POSTS_LIKES_{LK_PROFILE_ID}.csv')\n",
    "LK_PROFILE_POSTS_COMMENTS = path.join(LINKEDIN_INPUTS, f'LINKEDIN_PROFILE_POSTS_COMMENTS_{LK_PROFILE_ID}.csv')\n",
    "LK_PROFILE_ENGAGEMENTS = path.join(LINKEDIN_INPUTS, f'LINKEDIN_PROFILE_ENGAGEMENTS_{LK_PROFILE_ID}.csv')\n",
    "\n",
    "# LinkedIn Company DATABASES\n",
    "LK_COMPANY_POSTS = path.join(LINKEDIN_INPUTS, f'LINKEDIN_COMPANY_POSTS_{LK_COMPANY_ID}.csv')\n",
    "LK_COMPANY_FOLLOWERS = path.join(LINKEDIN_INPUTS, f'LINKEDIN_COMPANY_FOLLOWERS_{LK_COMPANY_ID}.csv')\n",
    "LK_COMPANY_POSTS_LIKES = path.join(LINKEDIN_INPUTS, f'LINKEDIN_COMPANY_POSTS_LIKES_{LK_COMPANY_ID}.csv')\n",
    "LK_COMPANY_POSTS_COMMENTS = path.join(LINKEDIN_INPUTS, f'LINKEDIN_COMPANY_POSTS_COMMENTS_{LK_COMPANY_ID}.csv')\n",
    "LK_COMPANY_ENGAGEMENTS = path.join(LINKEDIN_INPUTS, f'LINKEDIN_COMPANY_ENGAGEMENTS_{LK_COMPANY_ID}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feda35fe-76f9-4dd0-a29f-4f98deaa235b",
   "metadata": {},
   "source": [
    "### Setup YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c0cf02-1444-496d-a6f8-09ba06483d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YouTube credentials\n",
    "YOUTUBE_API_KEY = naas.secret.get('YOUTUBE_API_KEY')\n",
    "YOUTUBE_CHANNEL_URL = naas.secret.get('YOUTUBE_CHANNEL_URL')\n",
    "\n",
    "# Outputs folders\n",
    "YOUTUBE_INPUTS = path.join(\"YouTube\", \"Inputs\")\n",
    "if not path.exists(path.join(DIR, YOUTUBE_INPUTS)):\n",
    "    makedirs(path.join(DIR, YOUTUBE_INPUTS))\n",
    "\n",
    "YOUTUBE_OUTPUTS = path.join(\"YouTube\", \"Outputs\")\n",
    "if not path.exists(path.join(DIR, YOUTUBE_OUTPUTS)):\n",
    "    makedirs(path.join(DIR, YOUTUBE_OUTPUTS))\n",
    "\n",
    "# YouTube Channel info\n",
    "YT_CHANNEL_NAME = naas.secret.get('YOUTUBE_CHANNEL_NAME')\n",
    "YT_CHANNEL_ID = YOUTUBE_CHANNEL_URL.split(\"/channel/\")[-1].split(\"/\")[0]\n",
    "\n",
    "# YouTube\n",
    "YOUTUBE = \"YouTube\"\n",
    "YOUTUBE_LOGO = \"https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/YouTube_social_white_square_%282017%29.svg/300px-YouTube_social_white_square_%282017%29.svg.png\"\n",
    "YOUTUBE_COLOR = \"#FF0000\"\n",
    "\n",
    "# YouTube videos\n",
    "YT_VIDEOS = path.join(YOUTUBE_INPUTS, f'YOUTUBE_VIDEOS_{YT_CHANNEL_ID}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae43c0fb-4534-44ff-a058-82563e280a04",
   "metadata": {},
   "source": [
    "### Setup Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a209e4-3158-4dcb-a433-6c9e90d0b3ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Outputs folders\n",
    "TWITTER_INPUTS = path.join(\"Twitter\", \"Inputs\")\n",
    "if not path.exists(path.join(DIR, TWITTER_INPUTS)):\n",
    "    makedirs(path.join(DIR, TWITTER_INPUTS))\n",
    "\n",
    "TWITTER_OUTPUTS = path.join(\"Twitter\", \"Outputs\")\n",
    "if not path.exists(path.join(DIR, TWITTER_OUTPUTS)):\n",
    "    makedirs(path.join(DIR, TWITTER_OUTPUTS))\n",
    "\n",
    "# Twitter\n",
    "TWITTER = \"Twitter\"\n",
    "TWITTER_LOGO = \"https://sapiens-uspc.com/wp-content/uploads/2017/10/twitter-logo-vector.png\"\n",
    "TWITTER_COLOR = \"#1DA1F2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6088a3-5a9d-4174-94ad-c702b1c05ca5",
   "metadata": {},
   "source": [
    "### Get file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5764628f-032a-419f-83cd-d3682e6459ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_file_path(file_path):\n",
    "    if naas.is_production():\n",
    "        file_path = path.join(PROD_DIR, file_path)\n",
    "    else:\n",
    "        file_path = path.join(DEV_DIR, file_path)\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6ff4cf-cea6-420e-b190-5979156b5fed",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca771d93-9368-4077-8e0f-b4ef0f24c36d",
   "metadata": {},
   "source": [
    "### Get last posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe7a5e4-14e3-4f50-a0bc-d26a69a3c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_posts(df_notion, df_posts, owner, col_date=\"PUBLISHED_DATE\", update_all=False):\n",
    "    # Update all posts\n",
    "    df_update = df_posts.copy()\n",
    "    \n",
    "    if update_all:\n",
    "        return df_update\n",
    "\n",
    "    # Filter to get owner posts in Notion DB\n",
    "    if len(df_notion) > 0:\n",
    "        df_owner = df_notion[df_notion.Author == owner]\n",
    "        if len(df_owner) > 0:\n",
    "            df_update = df_update[:LINKEDIN_POSTS_UPDATE]        \n",
    "    return df_update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a6340d-0d16-42e2-b7a2-cc7c4c91e6de",
   "metadata": {},
   "source": [
    "### Get posts engagements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbb8755-507b-4506-b740-3a1269559361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_engagements(interaction, post_url):\n",
    "    df = pd.DataFrame()\n",
    "    try:\n",
    "        if interaction == \"LIKES\":\n",
    "            df = linkedin.connect(LI_AT, JSESSIONID).post.get_likes(post_url)\n",
    "        elif interaction == \"COMMENTS\":\n",
    "            df = linkedin.connect(LI_AT, JSESSIONID).post.get_comments(post_url)\n",
    "    except Exception as e:\n",
    "        if e.response.status_code:\n",
    "            print(e)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569a5fe8-71ab-4a75-b78a-0c924ccc8c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_engagements(df_posts,\n",
    "                        df_interaction,\n",
    "                        interaction,\n",
    "                        csv_output,\n",
    "                        no_posts=LINKEDIN_POSTS_UPDATE,\n",
    "                        min_updated_time=LINKEDIN_MIN_UPDATED_TIME):\n",
    "    # Init\n",
    "    df_out = df_interaction.copy()\n",
    "    \n",
    "    # Get all interactions if dataframe init empty or not complete\n",
    "    if len(df_posts) == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    if len(df_out) > 0:\n",
    "        if \"DATE_EXTRACT\" in df_out.columns:\n",
    "            last_update_date = df_out[\"DATE_EXTRACT\"].max()\n",
    "            time_last_update = datetime.now() - datetime.strptime(last_update_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "            minute_last_update = time_last_update.total_seconds() / 60\n",
    "            if minute_last_update > min_updated_time:\n",
    "                df_posts = df_posts[:no_posts]\n",
    "            else:\n",
    "                print(f\"ðŸ›‘ Nothing to update. Last update done {int(minute_last_update)} minutes ago.\")\n",
    "                return df_out.reset_index(drop=True)\n",
    "    else:\n",
    "        df_posts[\"SCENARIO\"] = pd.to_datetime(df_posts[\"PUBLISHED_DATE\"].str[:-6]).dt.strftime(PERIOD)\n",
    "        df_posts = df_posts[df_posts[\"SCENARIO\"] == datetime.now().strftime(PERIOD)].reset_index(drop=True)\n",
    "        \n",
    "    # Loop on posts\n",
    "    for index, row in df_posts.iterrows():\n",
    "        df_update = pd.DataFrame()\n",
    "        post_title = row.TITLE\n",
    "        post_author = row.AUTHOR_NAME\n",
    "        post_url = row.POST_URL\n",
    "        post_date = row.PUBLISHED_DATE\n",
    "        count_interactions = row[interaction]\n",
    "        print(f\"ðŸ”„ {index+1} - Update started on: '{post_title}' ({post_url})\")\n",
    "        \n",
    "        # Get interactions from post URL\n",
    "        if len(df_interaction) > 0:\n",
    "            tmp_df = df_interaction[df_interaction.POST_URL == post_url]\n",
    "            no_interactions = len(tmp_df)\n",
    "            if count_interactions != no_interactions:\n",
    "                print(f\"--> {count_interactions} post interaction count vs {no_interactions} interactions.\")\n",
    "                df_update = get_engagements(interaction, post_url)\n",
    "            else:\n",
    "                print(\"--->ðŸ›‘ Nothing to update.\")\n",
    "        else:\n",
    "            df_update = get_interactions(interaction, post_url)\n",
    "        \n",
    "        # Concat dataframe and save dataframe in CSV\n",
    "        if len(df_update) > 0:\n",
    "            print(f\"---> {len(df_update)} interactions fetched.\")\n",
    "            df_update['TITLE'] = post_title\n",
    "            df_update['AUTHOR_NAME'] = post_author\n",
    "            df_update['PUBLISHED_DATE'] = post_date\n",
    "            keys = [\"POST_URL\", \"PROFILE_ID\"]\n",
    "            if interaction == \"COMMENTS\":\n",
    "                keys = [\"POST_URL\", \"PROFILE_ID\", \"CREATED_TIME\"]\n",
    "            df_out = pd.concat([df_update, df_out]).drop_duplicates(keys, keep=\"first\")\n",
    "            output_path = save_data(df_out, csv_output)\n",
    "            \n",
    "    # Add dependency in production\n",
    "    print(f\"âœ… {len(df_out)} '{interaction}' fetched.\")\n",
    "    # Return all interactions\n",
    "    return df_out.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc2f99d-a532-4b38-b5e6-0fb450ce9a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_engagements_db(df_likes, df_comments):\n",
    "    # Init outputs\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # Dataframe likes\n",
    "    df_likes[\"REACTION\"] = \"LIKES\"\n",
    "\n",
    "    # Dataframe comments\n",
    "    df_comments[\"REACTION\"] = \"COMMENTS\"\n",
    "    \n",
    "    # Concat\n",
    "    df = pd.concat([df_likes, df_comments]).fillna(\"Not defined\").sort_values(by=\"PUBLISHED_DATE\", ascending=False)\n",
    "    \n",
    "    # Cleaning\n",
    "    to_keep = [\n",
    "        \"PROFILE_ID\",\n",
    "        \"PROFILE_URL\",\n",
    "        \"PUBLIC_ID\",\n",
    "        \"FIRSTNAME\",\n",
    "        \"LASTNAME\",\n",
    "        \"FULLNAME\",\n",
    "        \"OCCUPATION\",\n",
    "        \"REACTION\",\n",
    "        \"TEXT\",\n",
    "        \"TITLE\",\n",
    "        \"PUBLISHED_DATE\",\n",
    "        \"AUTHOR_NAME\",\n",
    "        \"POST_URL\",\n",
    "    ]\n",
    "    df = df[to_keep]\n",
    "    \n",
    "    print(f\"âœ… {len(df)} interactions fetched.\")\n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf29d45-afb7-43f0-abaa-7ed29ac62325",
   "metadata": {},
   "source": [
    "### Get fans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae70917-7a40-4c50-aa9f-bd08290adabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fans(df):\n",
    "    # Init\n",
    "    df_fans = df.copy()\n",
    "    \n",
    "    # Filter\n",
    "    df_fans[\"SCENARIO\"] = pd.to_datetime(df_fans[\"PUBLISHED_DATE\"].str[:-6]).dt.strftime(PERIOD)\n",
    "    df_fans = df_fans[(df_fans[\"SCENARIO\"] == datetime.now().strftime(PERIOD)) & (df_fans[\"FULLNAME\"] != OWNER)].reset_index(drop=True)\n",
    "\n",
    "    # Groupby\n",
    "    to_group = [\"PROFILE_URL\", \"FULLNAME\", \"OCCUPATION\"]\n",
    "    to_agg = {\"PROFILE_ID\": \"count\"}\n",
    "    \n",
    "    df_fans = df_fans.groupby(to_group, as_index=False).agg(to_agg)\n",
    "    df_fans = df_fans.sort_values(by=\"PROFILE_ID\", ascending=False).reset_index(drop=True)\n",
    "    return df_fans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688bb715-fc65-4aa1-a9a2-00315b0cb30b",
   "metadata": {},
   "source": [
    "### Get fans data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd615cd-e0b2-4492-9ba2-5a49f4db970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fans_data(df):\n",
    "    # Init\n",
    "    df_fans = df.copy()\n",
    "    \n",
    "    # Filter\n",
    "    df_fans = df_fans.drop_duplicates([\"PROFILE_ID\", \"REACTION\"], keep=\"last\").reset_index(drop=True)\n",
    "    df_fans[\"SCENARIO\"] = pd.to_datetime(df_fans[\"PUBLISHED_DATE\"].str[:-6]).dt.strftime(PERIOD)\n",
    "    df_fans = df_fans[(df_fans[\"SCENARIO\"] == datetime.now().strftime(PERIOD)) & (df_fans[\"FULLNAME\"] != OWNER)].reset_index(drop=True)\n",
    "    return df_fans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867518a5-3e83-4877-a145-5149735a1026",
   "metadata": {},
   "source": [
    "### Check fans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8947c22a-8cc9-4c3f-ae21-457c5d0db9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_new_fans(df_fans, df_update_fans):\n",
    "    # Concat data\n",
    "    df_out = pd.concat([df_update_fans, df_fans]).drop_duplicates([\"PROFILE_URL\", \"FULLNAME\", \"OCCUPATION\"], keep=False)\n",
    "    \n",
    "    if len(df_out) == 0:\n",
    "        return pd.DataFrame()\n",
    "    else:\n",
    "        return df_update_fans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccc9a0f-851e-4903-82c1-d1ef6b236ba8",
   "metadata": {},
   "source": [
    "### Transform UTC to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc45c72-18a8-413c-b5a9-0950b416570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utc_to_local(datetime_string,\n",
    "                 datetime_format='%Y-%m-%d %H:%M:%S%z',\n",
    "                 timezone=TIMEZONE):\n",
    "    # METHOD 1: Hardcode zones:\n",
    "    from_zone = tz.gettz('UTC')\n",
    "    to_zone = tz.gettz(timezone)\n",
    "\n",
    "    # utc = datetime.utcnow()\n",
    "    utc = datetime.strptime(datetime_string, datetime_format)\n",
    "\n",
    "    # Tell the datetime object that it's in UTC time zone since \n",
    "    # datetime objects are 'naive' by default\n",
    "    utc = utc.replace(tzinfo=from_zone)\n",
    "\n",
    "    # Convert time zone\n",
    "    local = utc.astimezone(to_zone)\n",
    "    return local#.strftime(DATETIME_FORMAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d91b17-16bd-4e12-b926-b0934207694f",
   "metadata": {},
   "source": [
    "### Get ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280d3d30-fb6b-497b-89b6-ad6f8381b36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranking(df_init,\n",
    "                col_label,\n",
    "                col_value,\n",
    "                agg_value,\n",
    "                label_max_len=100,\n",
    "                ranking=10):\n",
    "    # Init variable\n",
    "    df = df_init.copy()\n",
    "    \n",
    "    # Groupby period\n",
    "    df[col_value] = df[col_value].astype(float)\n",
    "    df = df.groupby(col_label, as_index=False).agg({col_value: agg_value})\n",
    "    \n",
    "    # Rename column\n",
    "    to_rename = {\n",
    "        col_label: \"LABEL\",\n",
    "        col_value: \"VALUE\"\n",
    "    }\n",
    "    df = df.rename(columns=to_rename)\n",
    "    \n",
    "    # Plotly: Label display\n",
    "    df[\"LABEL_D\"] = df.apply(lambda row: row[\"LABEL\"].split(\"?\")[0].split(\".\")[0], axis=1)\n",
    "    df[\"LABEL_D\"] = df.apply(lambda row: row[\"LABEL_D\"] if len(row[\"LABEL_D\"]) < 50 else row[\"LABEL_D\"][:47] + \"...\", axis=1)\n",
    "    \n",
    "    # Plotly: Value display\n",
    "    df[\"VALUE_D\"] = \"<b><span style='font-family: Arial;'>\" + df[\"VALUE\"].map(\"{:,.0f}\".format).str.replace(\",\", \" \") + \"</span></b>\"\n",
    "    \n",
    "    # Ranking\n",
    "    df = df.sort_values(by=\"VALUE\")\n",
    "    return df[-ranking:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bee4180-32cb-4c30-a795-630c187149fc",
   "metadata": {},
   "source": [
    "### Get views reach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6717a66b-8c38-412a-b9d4-30a0ec5d6928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_views_wdh(df_init,\n",
    "                  col_date,\n",
    "                  x_axis,\n",
    "                  y_axis,\n",
    "                  col_value,\n",
    "                  type_value\n",
    "                 ):\n",
    "    # Init variable\n",
    "    df = df_init.copy()\n",
    "        \n",
    "    # Setup date column and create X and Y axis analysis\n",
    "    df[col_value] = df[col_value].astype(int)\n",
    "    df[col_date] = pd.to_datetime(df[col_date].str[:18])\n",
    "    df[\"X_AXIS\"] = df[col_date].dt.strftime(x_axis)\n",
    "    df[\"Y_AXIS\"] = df[col_date].dt.strftime(y_axis)\n",
    "    df = df.rename(columns={col_value: \"VALUE\"})\n",
    "    \n",
    "    # Filter data\n",
    "    month_min = datetime.now() + relativedelta(months=-1)\n",
    "    df = df[df[col_date].dt.strftime(\"%Y%m\").astype(int) >= int(month_min.strftime(ORDER))]\n",
    "    \n",
    "    # Groupby\n",
    "    to_group = [\n",
    "        \"X_AXIS\",\n",
    "        \"Y_AXIS\",\n",
    "    ]\n",
    "    df = df.groupby(to_group, as_index=False).agg({\"VALUE\": type_value})\n",
    "    \n",
    "    # Create empty value\n",
    "    d = df[\"X_AXIS\"].max()\n",
    "    d2 = df[\"X_AXIS\"].min()\n",
    "    for x in range(int(d2), int(d)+1):\n",
    "        data = [\n",
    "            {\"X_AXIS\": x, \"Y_AXIS\": \"1\", \"VALUE\": 0},\n",
    "            {\"X_AXIS\": x, \"Y_AXIS\": \"2\", \"VALUE\": 0},\n",
    "            {\"X_AXIS\": x, \"Y_AXIS\": \"3\", \"VALUE\": 0},\n",
    "            {\"X_AXIS\": x, \"Y_AXIS\": \"4\", \"VALUE\": 0},\n",
    "            {\"X_AXIS\": x, \"Y_AXIS\": \"5\", \"VALUE\": 0},\n",
    "            {\"X_AXIS\": x, \"Y_AXIS\": \"6\", \"VALUE\": 0},\n",
    "            {\"X_AXIS\": x, \"Y_AXIS\": \"7\", \"VALUE\": 0},\n",
    "        ]\n",
    "        tmp_df = pd.DataFrame(data)\n",
    "        df = pd.concat([tmp_df, df])\n",
    "        \n",
    "    \n",
    "    # Group by with empty values\n",
    "    df[\"X_AXIS\"] = df[\"X_AXIS\"].astype(int)\n",
    "    df = df.groupby(to_group, as_index=False).agg({\"VALUE\": \"sum\"})\n",
    "        \n",
    "    # Sort values\n",
    "    df = df.sort_values(by=[\"X_AXIS\", \"Y_AXIS\"], ascending=[True, False])\n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a152fa9-d5b6-4c85-a249-06154ee918bf",
   "metadata": {},
   "source": [
    "### Get posts frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29718fb1-5834-4463-b79c-71a80e94eaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency(df_init,\n",
    "                  col_date,\n",
    "                  x_axis,\n",
    "                  y_axis,\n",
    "                  col_value,\n",
    "                  type_value\n",
    "                 ):\n",
    "    # Init variable\n",
    "    df = df_init.copy()\n",
    "    \n",
    "    # Setup date column and create X and Y axis analysis\n",
    "    df[col_date] = pd.to_datetime(df[col_date].str[:18])\n",
    "    df[\"X_AXIS\"] = df[col_date].dt.strftime(x_axis)\n",
    "    df[\"Y_AXIS\"] = df[col_date].dt.strftime(y_axis)\n",
    "    df = df.rename(columns={col_value: \"VALUE\"})\n",
    "    \n",
    "    # Groupby\n",
    "    to_group = [\n",
    "        \"X_AXIS\",\n",
    "        \"Y_AXIS\",\n",
    "    ]\n",
    "    df = df.groupby(to_group, as_index=False).agg({\"VALUE\": type_value})\n",
    "\n",
    "    # Create empty value\n",
    "    d = datetime.now() + MonthEnd(1)\n",
    "    d2 = df[\"X_AXIS\"].min()\n",
    "    idx = pd.date_range(d2, d, freq=\"m\", normalize=True)\n",
    "    for x in idx:\n",
    "        x = x.strftime(\"%Y-%m\")\n",
    "        data = [\n",
    "            {\"X_AXIS\": x, \"Y_AXIS\": \"1\", \"VALUE\": 0},\n",
    "            {\"X_AXIS\": x, \"Y_AXIS\": \"2\", \"VALUE\": 0},\n",
    "            {\"X_AXIS\": x, \"Y_AXIS\": \"3\", \"VALUE\": 0},\n",
    "            {\"X_AXIS\": x, \"Y_AXIS\": \"4\", \"VALUE\": 0},\n",
    "            {\"X_AXIS\": x, \"Y_AXIS\": \"5\", \"VALUE\": 0},\n",
    "            {\"X_AXIS\": x, \"Y_AXIS\": \"6\", \"VALUE\": 0},\n",
    "            {\"X_AXIS\": x, \"Y_AXIS\": \"7\", \"VALUE\": 0},\n",
    "        ]\n",
    "        tmp_df = pd.DataFrame(data)\n",
    "        df = pd.concat([tmp_df, df])\n",
    "        \n",
    "    # Group by with empty values\n",
    "    df = df.groupby(to_group, as_index=False).agg({\"VALUE\": \"sum\"})\n",
    "        \n",
    "    # Sort values\n",
    "    month_min = datetime.now() + relativedelta(months=-MONTH_ROLLING)\n",
    "    df = df[df[\"X_AXIS\"].str.replace(\"-\", \"\").astype(int) >= int(month_min.strftime(ORDER))]\n",
    "    df = df.sort_values(by=[\"X_AXIS\", \"Y_AXIS\"], ascending=[True, False])\n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df82816b-6b0c-40a7-a584-5d2c480b06d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T13:24:07.762195Z",
     "iopub.status.busy": "2022-06-30T13:24:07.761932Z",
     "iopub.status.idle": "2022-06-30T13:24:07.801929Z",
     "shell.execute_reply": "2022-06-30T13:24:07.801195Z",
     "shell.execute_reply.started": "2022-06-30T13:24:07.762170Z"
    },
    "tags": []
   },
   "source": [
    "### Get trend barchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea63938-efb7-4005-97c1-cfc0f6679fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trend(df_init,\n",
    "              col_date,\n",
    "              col_value,\n",
    "              agg_value,\n",
    "              period_rolling=MONTH_ROLLING):\n",
    "    # Init variable\n",
    "    df = df_init.copy()\n",
    "    \n",
    "    # Groupby period\n",
    "    if isinstance(col_value, list):\n",
    "        df[\"VALUE\"] = 0\n",
    "        for c in col_value:\n",
    "            df[c] = df[c].astype(float)\n",
    "            df[\"VALUE\"] = df[\"VALUE\"] + df[c]    \n",
    "        col_value = \"VALUE\"\n",
    "    elif agg_value == \"sum\":\n",
    "        df[col_value] = df[col_value].astype(float)\n",
    "    df[col_date] = pd.to_datetime(df[col_date].str[:-6]).dt.strftime(DATE_FORMAT)\n",
    "    df = df.groupby(col_date, as_index=False).agg({col_value: agg_value})\n",
    "    \n",
    "    # Rename column\n",
    "    to_rename = {\n",
    "        col_date: \"DATE_ISO\",\n",
    "        col_value: \"VALUE\"\n",
    "    }\n",
    "    df = df.rename(columns=to_rename)\n",
    "    \n",
    "    # Reindex value\n",
    "    d = datetime.now().date()\n",
    "    d2 = df.loc[df.index[0], \"DATE_ISO\"]\n",
    "    idx = pd.date_range(d2, d, freq = \"D\")    \n",
    "    df.set_index(\"DATE_ISO\", drop=True, inplace=True)\n",
    "    df.index = pd.DatetimeIndex(df.index)\n",
    "    df = df.reindex(idx, fill_value=0)\n",
    "    df[\"DATE_ISO\"] = pd.DatetimeIndex(df.index)\n",
    "    \n",
    "    # Groupby month\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"DATE_ISO\"], format=DATE_FORMAT).dt.strftime(PERIOD)\n",
    "    # Plotly: Date display\n",
    "    df[\"DATE_D\"] = pd.to_datetime(df[\"DATE_ISO\"], format=DATE_FORMAT).dt.strftime(PERIOD_D)\n",
    "    df = df.groupby([\"DATE\", \"DATE_D\"], as_index=False).agg({\"VALUE\": \"sum\"})\n",
    "\n",
    "    # Calc variation\n",
    "    for index, row in df.iterrows():\n",
    "        if index > 0:\n",
    "            n = df.loc[df.index[index], \"VALUE\"]\n",
    "            n_1 = df.loc[df.index[index-1], \"VALUE\"]\n",
    "            df.loc[df.index[index], \"VALUE_COMP\"] = n_1\n",
    "            df.loc[df.index[index], \"VARV\"] = n - n_1\n",
    "            if n_1 > 0:\n",
    "                df.loc[df.index[index], \"VARP\"] = (n - n_1) / abs(n_1)\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    # Plotly: Value display\n",
    "    df[\"VALUE_D\"] = \"<b><span style='font-family: Arial;'>\" + df[\"VALUE\"].map(\"{:,.0f}\".format).str.replace(\",\", \" \") + \"</span></b>\"\n",
    "    \n",
    "    # Plotly: Variation display\n",
    "    df[\"VARV_D\"] = df[\"VARV\"].map(\"{:,.0f}\".format).str.replace(\",\", \" \")\n",
    "    df.loc[df[\"VARV\"] >= 0, \"VARV_D\"] = \"+\" + df[\"VARV_D\"]\n",
    "    df[\"VARP_D\"] = df[\"VARP\"].map(\"{:,.0%}\".format).str.replace(\",\", \" \")\n",
    "    df.loc[df[\"VARP\"] >= 0, \"VARP_D\"] = \"+\" + df[\"VARP_D\"]\n",
    "    \n",
    "    # Plotly: hovertext\n",
    "    df[\"TEXT\"] = (\"<b><span style='font-size: 14px;'>\" + df[\"DATE_D\"].astype(str) + \": \" + df[\"VALUE_D\"] + \"</span></b><br>\"\n",
    "                  \"<span style='font-size: 12px;'>\" + f\"{PERIOD_TEXT}: \" + df[\"VARV_D\"] + \" (\" + df[\"VARP_D\"] + \")</span>\")\n",
    "    \n",
    "    # Return month rolling\n",
    "    return df[-period_rolling:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b34dba2-f457-4400-9a3e-c23cfe886c6d",
   "metadata": {},
   "source": [
    "### Get trend barline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bda0732-bcc1-4da0-9652-e398490de371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trend_barline(df_init,\n",
    "                      col_date,\n",
    "                      col_value,\n",
    "                      agg_value,\n",
    "                      period_rolling=MONTH_ROLLING):\n",
    "    # Init variable\n",
    "    df = df_init.copy()\n",
    "    \n",
    "    # Groupby period\n",
    "    df[col_date] = pd.to_datetime(df[col_date]).dt.strftime(PERIOD)\n",
    "    df = df.groupby(col_date, as_index=False).agg({col_value: agg_value})\n",
    "    \n",
    "    # Rename column\n",
    "    to_rename = {\n",
    "        col_date: \"DATE_ISO\",\n",
    "        col_value: \"VARV\"\n",
    "    }\n",
    "    df = df.rename(columns=to_rename)\n",
    "    \n",
    "    # Reindex value\n",
    "    d = datetime.now().date()\n",
    "    d2 = df.loc[df.index[0], \"DATE_ISO\"]\n",
    "    idx = pd.date_range(d2, d, freq = \"D\")    \n",
    "    df.set_index(\"DATE_ISO\", drop=True, inplace=True)\n",
    "    df.index = pd.DatetimeIndex(df.index)\n",
    "    df = df.reindex(idx, fill_value=0)\n",
    "    df[\"DATE_ISO\"] = pd.DatetimeIndex(df.index)\n",
    "    \n",
    "    # Groupby month\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"DATE_ISO\"], format=DATE_FORMAT).dt.strftime(PERIOD)\n",
    "    # Plotly: Date display\n",
    "    df[\"DATE_D\"] = pd.to_datetime(df[\"DATE_ISO\"], format=DATE_FORMAT).dt.strftime(PERIOD_D)\n",
    "    df = df.groupby([\"DATE\", \"DATE_D\"], as_index=False).agg({\"VARV\": \"sum\"})\n",
    "    \n",
    "    # Add value col\n",
    "    df.insert(loc=2, column=\"VALUE\", value=df[\"VARV\"].cumsum())\n",
    "    df.insert(loc=3, column=\"VALUE_COMP\", value=df[\"VALUE\"] - df[\"VARV\"])\n",
    "    df[\"VARP\"] = df[\"VARV\"] / df[\"VALUE_COMP\"]\n",
    "    \n",
    "    # Plotly: Value display\n",
    "    df[\"VALUE_D\"] = \"<b><span style=font-size: 16px; style=font-family: Arial>\" + df[\"VALUE\"].map(\"{:,.0f}\".format).str.replace(\",\", \" \") + \"</span></b>\"\n",
    "    \n",
    "    # Plotly: Variation display\n",
    "    df[\"VARV_D\"] = df[\"VARV\"].map(\"{:,.0f}\".format).str.replace(\",\", \" \")\n",
    "    df.loc[df[\"VARV\"] >= 0, \"VARV_D\"] = \"+\" + df[\"VARV_D\"]\n",
    "    df[\"VARP_D\"] = df[\"VARP\"].map(\"{:,.0%}\".format).str.replace(\",\", \" \")\n",
    "    df.loc[df[\"VARP\"] >= 0, \"VARP_D\"] = \"+\" + df[\"VARP_D\"]\n",
    "    \n",
    "    # Plotly: hovertext\n",
    "    df[\"TEXT\"] = (\"<b><span style='font-size: 14px;'>\" + df[\"DATE_D\"].astype(str) + \": \" + df[\"VALUE_D\"] + \"</span></b><br>\"\n",
    "                  \"<span style='font-size: 12px;'>\" + f\"{PERIOD_TEXT}: \" + df[\"VARV_D\"] + \" (\" + df[\"VARP_D\"] + \")</span>\")\n",
    "    \n",
    "    # Return month rolling\n",
    "    return df[-period_rolling:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e2a98d-9404-41d9-a7ef-493f5277ddb6",
   "metadata": {},
   "source": [
    "### Get trend linechart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daae756c-1ad0-4630-8b0f-9aca700db113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trend_linechart(df_init,\n",
    "                        col_date,\n",
    "                        col_value,\n",
    "                        agg_value,\n",
    "                        period_rolling=MONTH_ROLLING):\n",
    "    # Init variable\n",
    "    df = df_init.copy()\n",
    "    \n",
    "    # Groupby period\n",
    "    df[\"ENGAGEMENTS\"] = df[\"LIKES\"].astype(int) + df[\"COMMENTS\"].astype(int)  + df[\"SHARES\"].astype(int)\n",
    "    df[\"VIEWS\"] = df[\"VIEWS\"].astype(int)\n",
    "    df[col_date] = pd.to_datetime(df[col_date].str[:-6]).dt.strftime(PERIOD)\n",
    "    df = df.groupby(col_date, as_index=False).agg({\"ENGAGEMENTS\": agg_value, \"VIEWS\": agg_value})\n",
    "    \n",
    "    # Rename column\n",
    "    to_rename = {\n",
    "        col_date: \"DATE_ISO\",\n",
    "    }\n",
    "    df = df.rename(columns=to_rename)\n",
    "    \n",
    "    # Reindex value\n",
    "    d = datetime.now().date()\n",
    "    d2 = df.loc[df.index[0], \"DATE_ISO\"]\n",
    "    idx = pd.date_range(d2, d, freq = \"D\")    \n",
    "    df.set_index(\"DATE_ISO\", drop=True, inplace=True)\n",
    "    df.index = pd.DatetimeIndex(df.index)\n",
    "    df = df.reindex(idx, fill_value=0)\n",
    "    df[\"DATE_ISO\"] = pd.DatetimeIndex(df.index)\n",
    "    \n",
    "    # Groupby month\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"DATE_ISO\"], format=DATE_FORMAT).dt.strftime(PERIOD)\n",
    "    # Plotly: Date display\n",
    "    df[\"DATE_D\"] = pd.to_datetime(df[\"DATE_ISO\"], format=DATE_FORMAT).dt.strftime(PERIOD_D)\n",
    "    df = df.groupby([\"DATE\", \"DATE_D\"], as_index=False).agg({\"ENGAGEMENTS\": agg_value, \"VIEWS\": agg_value})\n",
    "    df[\"VALUE\"] = df[\"ENGAGEMENTS\"].astype(int) / df[\"VIEWS\"].astype(int)\n",
    "\n",
    "    # Calc variation\n",
    "    for index, row in df.iterrows():\n",
    "        if index > 0:\n",
    "            n = df.loc[df.index[index], \"VALUE\"]\n",
    "            n_1 = df.loc[df.index[index-1], \"VALUE\"]\n",
    "            df.loc[df.index[index], \"VALUE_COMP\"] = n_1\n",
    "            df.loc[df.index[index], \"VARV\"] = n - n_1\n",
    "            if n_1 > 0:\n",
    "                df.loc[df.index[index], \"VARP\"] = (n - n_1) / abs(n_1)\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    # Plotly: Date display\n",
    "    df[\"DATE_D\"] = pd.to_datetime(df[\"DATE\"], format=PERIOD).dt.strftime(PERIOD_D)\n",
    "    \n",
    "    # Plotly: Value display\n",
    "    df[\"VALUE_D\"] = \"<b><span style=font-size: 16px; style=font-family: Arial>\" + df[\"VALUE\"].map(\"{:,.2%}\".format).str.replace(\",\", \" \") + \"</span></b>\"\n",
    "    \n",
    "    # Plotly: Variation display\n",
    "    df[\"VARV_D\"] = (df[\"VARV\"] * 100).map(\"{:,.2f} pts\".format).str.replace(\",\", \" \")\n",
    "    df.loc[df[\"VARV\"] >= 0, \"VARV_D\"] = \"+\" + df[\"VARV_D\"]\n",
    "    df[\"VARP_D\"] = df[\"VARP\"].map(\"{:,.0%}\".format).str.replace(\",\", \" \")\n",
    "    df.loc[df[\"VARP\"] >= 0, \"VARP_D\"] = \"+\" + df[\"VARP_D\"]\n",
    "    \n",
    "    # Plotly: hovertext\n",
    "    df[\"TEXT\"] = (\"<b><span style='font-size: 14px;'>\" + df[\"DATE_D\"].astype(str) + \": \" + df[\"VALUE_D\"] + \"</span></b><br>\"\n",
    "                  \"<span style='font-size: 12px;'>\" + f\"{PERIOD_TEXT}: \" + df[\"VARV_D\"] + \" (\" + df[\"VARP_D\"] + \")</span>\")\n",
    "    \n",
    "    # Return month rolling\n",
    "    return df[-period_rolling:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0774af26-098b-462c-9350-8e9fe1a60144",
   "metadata": {},
   "source": [
    "### Get notion content db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15bb4ee-fe84-413f-95eb-0be273fe6a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notion_df(database_url):\n",
    "    # Get pages\n",
    "    database_id = database_url.split(\"/\")[-1].split(\"?v=\")[0]\n",
    "    pages = notion.connect(NOTION_TOKEN).database.query(database_id, query={})\n",
    "    if len(pages) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Rename columns\n",
    "    columns = pages[0].df().Name.tolist()\n",
    "    to_rename = {}\n",
    "    for i, v in enumerate(columns):\n",
    "        to_rename[i] = v\n",
    "    \n",
    "    # Create dataframe from pages\n",
    "    df = pd.DataFrame()\n",
    "    for page in pages:\n",
    "        values = page.df().drop(\"Type\", axis=1).to_dict().get(\"Value\")\n",
    "        tmp_df = pd.DataFrame([values]).rename(columns=to_rename)\n",
    "        content_url = tmp_df.loc[0, \"Content URL\"]\n",
    "        if content_url == \"None\":\n",
    "            notion.connect(NOTION_TOKEN).blocks.delete(page.id)\n",
    "        else:\n",
    "            df = pd.concat([df, tmp_df])\n",
    "\n",
    "    df = df.sort_values(by=\"Publication Date\", ascending=False).reset_index(drop=True)\n",
    "    print(\"âœ… Notion content DB:\", len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8495ce5c-02a0-479e-a896-0c4f4636bf3d",
   "metadata": {},
   "source": [
    "### Create horizontal barchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3f1a8d-b503-4023-a537-7bee7e697654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_horizontal_barchart(df,\n",
    "                               label=\"LABEL_D\",\n",
    "                               value=\"VALUE\",\n",
    "                               value_d=\"VALUE_D\"):\n",
    "    # Init\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Create fig\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            y=df[label],\n",
    "            x=df[value],\n",
    "            text=df[value_d],\n",
    "            textposition=\"outside\",\n",
    "            marker=dict(color=COLOR),\n",
    "            orientation=\"h\"\n",
    "        )\n",
    "    )\n",
    "    # Add logo\n",
    "    fig.add_layout_image(\n",
    "        dict(\n",
    "            source=LOGO,\n",
    "            xref=\"paper\",\n",
    "            yref=\"paper\",\n",
    "            x=-0.28,\n",
    "            y=1.035,\n",
    "            sizex=0.15,\n",
    "            sizey=0.15,\n",
    "            xanchor=\"right\",\n",
    "            yanchor=\"bottom\"\n",
    "        )\n",
    "    )\n",
    "    fig.update_traces(showlegend=False)\n",
    "    # Plotly: Create title\n",
    "    total_value = \"{:,.0f}\".format(df[value].sum()).replace(\",\", \" \")\n",
    "    title = f\"<b><span style='font-size: 20px;'>{TITLE}</span></b><br><span style='font-size: 18px;'>Total {KPI_TITLE.lower()}: {total_value}</span>\"\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        title_x=0.09,\n",
    "        title_font=dict(family=\"Arial\", color=\"black\"),\n",
    "        paper_bgcolor=\"#ffffff\",\n",
    "        plot_bgcolor=\"#ffffff\",\n",
    "        width=1200,\n",
    "        height=600,\n",
    "        margin_pad=10,\n",
    "        margin_r=10,\n",
    "        margin_l=10,\n",
    "    )\n",
    "    fig.update_xaxes(showticklabels=False)\n",
    "    fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c605f360-3459-40d1-a68b-227f38a6684e",
   "metadata": {},
   "source": [
    "### Create barchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d7da29-4c45-4758-995b-20b858a2aa72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_barchart(df,\n",
    "                    label=\"DATE_D\",\n",
    "                    value=\"VALUE\",\n",
    "                    value_d=\"VALUE_D\",\n",
    "                    text=\"TEXT\"):\n",
    "    # Init\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Create fig\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=df[label],\n",
    "            y=df[value],\n",
    "            text=df[value_d],\n",
    "            textposition=\"outside\",\n",
    "            hoverinfo=\"text\",\n",
    "            hovertext=df[text],\n",
    "            marker=dict(color=COLOR)\n",
    "        )\n",
    "    )\n",
    "    # Add logo\n",
    "    fig.add_layout_image(\n",
    "        dict(\n",
    "            source=LOGO,\n",
    "            xref=\"paper\",\n",
    "            yref=\"paper\",\n",
    "            x=0.01,\n",
    "            y=1.045,\n",
    "            sizex=0.12,\n",
    "            sizey=0.12,\n",
    "            xanchor=\"right\",\n",
    "            yanchor=\"bottom\"\n",
    "        )\n",
    "    )\n",
    "    fig.update_traces(showlegend=False)\n",
    "    # Plotly: Create title\n",
    "    total_value = \"{:,.0f}\".format(df[value].sum()).replace(\",\", \" \")\n",
    "    varv = df.loc[df.index[-1], \"VARV\"]\n",
    "    varp = df.loc[df.index[-1], \"VARP\"]\n",
    "    varv_d = \"{:,.0f}\".format(varv).replace(\",\", \" \")\n",
    "    varp_d = \"{:,.0%}\".format(varp).replace(\",\", \" \")\n",
    "    if varv >= 0:\n",
    "        varv_d = f\"+{varv_d}\"\n",
    "        varp_d = f\"+{varp_d}\"\n",
    "    title = f\"<b><span style='font-size: 20px;'>{TITLE}</span></b><br><span style='font-size: 18px;'>Total: {total_value} | {PERIOD_TEXT}: {varv_d} ({varp_d})</span>\"\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        title_x=0.09,\n",
    "        title_font=dict(family=\"Arial\", color=\"black\"),\n",
    "        paper_bgcolor=\"#ffffff\",\n",
    "        plot_bgcolor=\"#ffffff\",\n",
    "#         autosize=True,\n",
    "        width=1200,\n",
    "        height=600,\n",
    "        margin_pad=10,\n",
    "    )\n",
    "#     config = {'displayModeBar': False, \"responsive\": True}\n",
    "#     fig.show(config=config)\n",
    "    fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525d322c-7774-440b-a323-5f9a8f2ad25b",
   "metadata": {},
   "source": [
    "### Create barlinechart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d92983-2b7e-4207-a92f-b98e6026b37d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_barlinechart(df,\n",
    "                        label=\"DATE_D\",\n",
    "                        value=\"VALUE\",\n",
    "                        value_d=\"VALUE_D\",\n",
    "                        text=\"TEXT\",\n",
    "                        yaxes_left=None,\n",
    "                        yaxes_right=None):\n",
    "    # Init\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Create figure with secondary y-axis\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "    # Add traces\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=df[label],\n",
    "            y=df[\"VARV\"],\n",
    "            textposition=\"outside\",\n",
    "            hoverinfo=\"text\",\n",
    "            hovertext=df[text],\n",
    "            marker=dict(color=COLOR2)\n",
    "        ),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df[label],\n",
    "            y=df[value],\n",
    "            mode=\"lines+markers+text\",\n",
    "            hoverinfo=\"text\",\n",
    "            text=df[value_d],\n",
    "            textposition=\"top left\",\n",
    "            hovertext=df[text],\n",
    "            line=dict(color=COLOR, width=4),\n",
    "        ),\n",
    "        secondary_y=True,\n",
    "    )\n",
    "    # Set y-axes titles\n",
    "    fig.update_yaxes(\n",
    "        title_text=yaxes_left,\n",
    "        title_font=dict(family=\"Arial\", size=14, color=\"black\"),\n",
    "        secondary_y=False\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        title_text=yaxes_right,\n",
    "        title_font=dict(family=\"Arial\", size=14, color=\"black\"),\n",
    "        secondary_y=True\n",
    "    )\n",
    "    # Add logo\n",
    "    fig.add_layout_image(\n",
    "        dict(\n",
    "            source=LOGO,\n",
    "            xref=\"paper\",\n",
    "            yref=\"paper\",\n",
    "            x=0.01,\n",
    "            y=1.045,\n",
    "            sizex=0.12,\n",
    "            sizey=0.12,\n",
    "            xanchor=\"right\",\n",
    "            yanchor=\"bottom\"\n",
    "        )\n",
    "    )\n",
    "    fig.update_traces(showlegend=False)\n",
    "    # Plotly: Create title\n",
    "    total_value = \"{:,.0f}\".format(df.loc[df.index[-1], \"VALUE\"]).replace(\",\", \" \")\n",
    "    varv = df.loc[df.index[-1], \"VARV\"]\n",
    "    varp = df.loc[df.index[-1], \"VARP\"]\n",
    "    varv_d = \"{:,.0f}\".format(varv).replace(\",\", \" \")\n",
    "    varp_d = \"{:,.0%}\".format(varp).replace(\",\", \" \")\n",
    "    if varv >= 0:\n",
    "        varv_d = f\"+{varv_d}\"\n",
    "        varp_d = f\"+{varp_d}\"\n",
    "    title = f\"<b><span style='font-size: 20px;'>{TITLE}</span></b><br><span style='font-size: 18px;'>Total: {total_value} | {PERIOD_TEXT}: {varv_d} ({varp_d})</span>\"\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        title_x=0.09,\n",
    "        title_font=dict(family=\"Arial\", color=\"black\"),\n",
    "        paper_bgcolor=\"#ffffff\",\n",
    "        plot_bgcolor=\"#ffffff\",\n",
    "        width=1200,\n",
    "        height=600,\n",
    "        margin_pad=10,\n",
    "    )\n",
    "    fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caa17e9-968b-4de9-b365-05f76f000b41",
   "metadata": {},
   "source": [
    "### Create linechart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8425f488-a426-4144-9a63-2098cac3bd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_linechart(df,\n",
    "                    label=\"DATE_D\",\n",
    "                    value=\"VALUE\",\n",
    "                    value_d=\"VALUE_D\",\n",
    "                    text=\"TEXT\"):\n",
    "    # Init\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Create fig\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df[label],\n",
    "            y=df[value],\n",
    "            mode=\"lines+markers+text\",\n",
    "            text=df[value_d],\n",
    "            textposition=\"top center\",\n",
    "            hoverinfo=\"text\",\n",
    "            hovertext=df[text],\n",
    "            line=dict(color=COLOR, width=4),\n",
    "        )\n",
    "    )\n",
    "    # Add logo\n",
    "    fig.add_layout_image(\n",
    "        dict(\n",
    "            source=LOGO,\n",
    "            xref=\"paper\",\n",
    "            yref=\"paper\",\n",
    "            x=0.01,\n",
    "            y=1.045,\n",
    "            sizex=0.12,\n",
    "            sizey=0.12,\n",
    "            xanchor=\"right\",\n",
    "            yanchor=\"bottom\"\n",
    "        )\n",
    "    )\n",
    "    fig.update_traces(showlegend=False)\n",
    "    # Plotly: Create title\n",
    "    total_eng = df[\"ENGAGEMENTS\"].sum()\n",
    "    total_views = df[\"VIEWS\"].sum()\n",
    "    total_value = \"{:,.2%}\".format(total_eng / total_views).replace(\",\", \" \")\n",
    "    varv = df.loc[df.index[-1], \"VARV\"] * 100\n",
    "    varp = df.loc[df.index[-1], \"VARP\"]\n",
    "    varv_d = \"{:,.2f} pts\".format(varv).replace(\",\", \" \")\n",
    "    varp_d = \"{:,.0%}\".format(varp).replace(\",\", \" \")\n",
    "    if varv >= 0:\n",
    "        varv_d = f\"+{varv_d}\"\n",
    "        varp_d = f\"+{varp_d}\"\n",
    "    title = f\"<b><span style='font-size: 20px;'>{TITLE}</span></b><br><span style='font-size: 18px;'>Average: {total_value} | {PERIOD_TEXT}: {varv_d} ({varp_d})</span>\"\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        title_x=0.09,\n",
    "        title_font=dict(family=\"Arial\", color=\"black\"),\n",
    "        paper_bgcolor=\"#ffffff\",\n",
    "        plot_bgcolor=\"#ffffff\",\n",
    "        width=1200,\n",
    "        height=600,\n",
    "        margin_pad=10,\n",
    "        yaxis = dict(\n",
    "            range=[0, df[value].max() * 1.1],\n",
    "            tickmode='array',\n",
    "            tickformat='.1%'\n",
    "        )\n",
    "    )\n",
    "    fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7db782-b025-48ef-ac71-89a73a443b4b",
   "metadata": {},
   "source": [
    "### Create heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56a744a-0dcb-4d85-bbfa-eb83a7f84afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heatmap(df,\n",
    "                   x_value=\"X_AXIS\",\n",
    "                   y_value=\"Y_AXIS\",\n",
    "                   z_value=\"VALUE\",\n",
    "                   x_format=\"%H\",\n",
    "                   x_format_d=\"%H\",\n",
    "                   text=\"views\",\n",
    "                   ):\n",
    "    \n",
    "    # Add display values\n",
    "    df[\"X_AXIS_D\"] = pd.to_datetime(df[x_value], format=x_format).dt.strftime(x_format_d)\n",
    "    df[\"Y_AXIS_D\"] = df.apply(lambda row: calendar.day_name[int(row[y_value]) - 1], axis=1)\n",
    "    df[\"TEXT\"] = df[z_value].astype(str) + f\" {text} on \" + df[\"Y_AXIS_D\"] + \"s, \" + df[\"X_AXIS_D\"]\n",
    "\n",
    "    # Create graph data\n",
    "    x = sorted(df[x_value].unique().tolist())\n",
    "    y = sorted(df[y_value].unique().tolist(), reverse=True)\n",
    "    def get_values(df, y, value):\n",
    "        values = []\n",
    "        for i in y:\n",
    "            tmp = df[df[y_value] == i].reset_index(drop=True)\n",
    "            data = tmp[value].tolist()\n",
    "            values.append(data)\n",
    "        return values\n",
    "    z = get_values(df, y, z_value)\n",
    "    hovertext = get_values(df, y, \"TEXT\")\n",
    "    \n",
    "    # Colors\n",
    "    colors = [\n",
    "        [0.00, \"#e7f4fa\"],\n",
    "        [0.01, \"#b7def1\"],\n",
    "        [0.25, \"#88c9e8\"],\n",
    "        [0.50, \"#59b3df\"],\n",
    "        [1.00, \"#1293d2\"]\n",
    "    ]\n",
    "\n",
    "    # Create fig\n",
    "    fig = go.Figure(\n",
    "        data=go.Heatmap(\n",
    "            x=df[\"X_AXIS_D\"].unique().tolist(),\n",
    "            y=df[\"Y_AXIS_D\"].unique().tolist(),\n",
    "            z=z,\n",
    "            text=hovertext,\n",
    "            hoverinfo=\"text\",\n",
    "            type='heatmap',\n",
    "            colorscale=colors,\n",
    "            hoverongaps=False,\n",
    "        )\n",
    "    )\n",
    "    fig.add_layout_image(\n",
    "        dict(\n",
    "            source=LOGO,\n",
    "            xref=\"paper\",\n",
    "            yref=\"paper\",\n",
    "            x=-0.01,\n",
    "            y=1.045,\n",
    "            sizex=0.12,\n",
    "            sizey=0.12,\n",
    "            xanchor=\"right\",\n",
    "            yanchor=\"bottom\"\n",
    "        )\n",
    "    )\n",
    "    fig.update_traces(xgap=10,\n",
    "                      ygap=10,\n",
    "                      selector=dict(type='heatmap'),\n",
    "                      showscale=False)\n",
    "    total_value = \"{:,.0f}\".format(df[z_value].sum()).replace(\",\", \" \")\n",
    "    fig.update_layout(\n",
    "        title = f\"<b><span style='font-size: 20px;'>{TITLE}</span></b><br><span style='font-size: 18px;'>Total {text}: {total_value}</span>\",\n",
    "        title_x=0.08,\n",
    "        title_font=dict(family=\"Arial\", size=20, color=\"black\"),\n",
    "        plot_bgcolor=\"#ffffff\",\n",
    "        width=1200,\n",
    "        height=600,\n",
    "        yaxis_scaleanchor=\"x\"\n",
    "    )\n",
    "    fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5490e16-84e1-494d-a165-c5ac998346d0",
   "metadata": {},
   "source": [
    "### Calc variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88316b4-7767-4438-b460-39b12a666bb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_value(df_init, value=\"VALUE\", value_comp=\"VALUE_COMP\", varv=\"VARV\", varp=\"VARP\"):\n",
    "    v1 = 0\n",
    "    v2 = 0\n",
    "    v3 = 0\n",
    "    v4 = 0\n",
    "    df = df_init.reset_index(drop=True)\n",
    "    if len(df) > 0:\n",
    "        if value in df.columns:\n",
    "            v1 = df.loc[df.index[-1], value]\n",
    "        if value_comp in df.columns:\n",
    "            v2 = df.loc[df.index[-1], value_comp]\n",
    "        if varv in df.columns:\n",
    "            v3 = df.loc[df.index[-1], varv]\n",
    "        if varp in df.columns:\n",
    "            v4 = df.loc[df.index[-1], varp]\n",
    "        return v1, v2, v3, v4\n",
    "    else:\n",
    "        return 0, 0, 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1552d28-4e64-4d99-8958-a4f5b9c8d40c",
   "metadata": {},
   "source": [
    "### Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efab7b4-7c29-459f-9adc-d9d331930cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GIT_REPO_NAME = naas.secret.get(\"GIT_REPO_NAME\")\n",
    "\n",
    "def run_pipeline(pipeline, folder):\n",
    "    for notebook in pipeline:\n",
    "        print(\"âž¡ï¸ Started running notebook:\", notebook)\n",
    "        if not path.exists(notebook):\n",
    "            notebook = path.join(GIT_REPO_NAME, folder, notebook)\n",
    "        %run \"$notebook\"\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d856dbf2-37a4-4e52-804a-81c3728b99a7",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df05909e-bfcf-4acc-a187-1c5e548c4842",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-23T07:28:50.900828Z",
     "iopub.status.busy": "2022-06-23T07:28:50.900591Z",
     "iopub.status.idle": "2022-06-23T07:28:50.904914Z",
     "shell.execute_reply": "2022-06-23T07:28:50.904289Z",
     "shell.execute_reply.started": "2022-06-23T07:28:50.900804Z"
    },
    "tags": []
   },
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a050513a-75db-4784-9480-b7cc64bd1a86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_data(df, file_path, storage=\"Naas\"):\n",
    "    output_path = None\n",
    "    if len(df) > 0:\n",
    "        df[\"DATE_EXTRACT\"] = datetime.now().strftime(DATETIME_FORMAT)\n",
    "    try:\n",
    "        if storage == \"Naas\":\n",
    "            if not naas.is_production():\n",
    "                output_path = path.join(DEV_DIR, file_path)\n",
    "                df.to_csv(output_path, index=False)\n",
    "                naas.dependency.add(output_path)\n",
    "            else:\n",
    "                output_path = path.join(PROD_DIR, file_path)\n",
    "                df.to_csv(output_path, index=False)\n",
    "            print(\"âœ… Dataframe successfully saved in CSV:\", file_path)\n",
    "        elif storage == \"AWS\":\n",
    "            output_path = file_path\n",
    "            wr.s3.to_parquet(\n",
    "                df=df.astype(str),\n",
    "                path=file_path,\n",
    "                dataset=True,\n",
    "                mode=\"overwrite\"\n",
    "            )\n",
    "            print(\"âœ… Dataframe successfully saved in AWS:\", file_path)\n",
    "    except Exception as e:\n",
    "        return e\n",
    "#     return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190f8e54-8c31-4297-9a7c-ab9ad44ec67d",
   "metadata": {},
   "source": [
    "### Save asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9b9b07-37a1-4957-a667-9b393862be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_graph_asset(obj, file_path, image=False):\n",
    "    # Get output\n",
    "    if naas.is_production():\n",
    "        output_path = path.join(PROD_DIR, file_path)\n",
    "    else:\n",
    "        output_path = path.join(DEV_DIR, file_path)\n",
    "        \n",
    "    # Save asset\n",
    "    if file_path.endswith(\".csv\"):\n",
    "        obj[\"DATE_EXTRACT\"] = datetime.now().strftime(DATETIME_FORMAT)\n",
    "        obj.to_csv(output_path, index=False)\n",
    "    elif file_path.endswith(\".html\"):\n",
    "        obj.write_html(output_path)\n",
    "    elif file_path.endswith(\".png\") and not image:\n",
    "        obj.write_image(output_path)\n",
    "    elif file_path.endswith(\".png\") and image:\n",
    "        obj.to_file(output_path)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e43f9c-88b5-41b1-b210-fe7e4c9983dd",
   "metadata": {},
   "source": [
    "### Get logo from platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b8660b-8f71-4481-a415-cbb066824ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logo(platform, page_icon):\n",
    "    # Manage page icon\n",
    "    if page_icon is None:\n",
    "        if platform == LINKEDIN:\n",
    "            page_icon = LINKEDIN_LOGO\n",
    "        elif platform == YOUTUBE:\n",
    "            page_icon = YOUTUBE_LOGO\n",
    "        elif platform == TWITTER:\n",
    "            page_icon = TWITTER_LOGO\n",
    "    return page_icon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda327d7-77b7-4a60-9e5e-9a93ce82a9a7",
   "metadata": {},
   "source": [
    "### Delte page blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245d8b69-b924-49a6-80e6-37cee65e83c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_page_blocks(page):  \n",
    "    # Delete all blocks\n",
    "    blocks = page.get_blocks()\n",
    "    if len(blocks) > 0:\n",
    "        while True:\n",
    "            for block in blocks:\n",
    "                notion.connect(NOTION_TOKEN).blocks.delete(block.id)\n",
    "            blocks = page.get_blocks()\n",
    "            if len(blocks) == 0:\n",
    "                break\n",
    "    page.update()\n",
    "    return page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b6f6ab-a6ba-4004-9924-3800e5ea6321",
   "metadata": {},
   "source": [
    "### Update \"Report\" Notion DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b5c4bf-f45d-4452-887c-02f16f86ec88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_report_status(report,\n",
    "                         platform,\n",
    "                         owner,\n",
    "                         df=pd.DataFrame(),\n",
    "                         image_link=None,\n",
    "                         html_link=None,\n",
    "                         csv_link=None,\n",
    "                         page_icon=None,\n",
    "                         ):\n",
    "    # Create asset dataframe\n",
    "    new_asset = {\n",
    "        \"REPORT\": report,\n",
    "        \"PLATFORM\": platform,\n",
    "        \"OWNER\": owner,\n",
    "        \"IMAGE_LINK\": image_link,\n",
    "        \"HTML_LINK\": html_link,\n",
    "        \"CSV_LINK\": csv_link,\n",
    "        \"DATE_EXTRACT\": None,\n",
    "    }\n",
    "    # Get asset\n",
    "    df_asset = get_data(ASSETS)\n",
    "    if naas.is_production():\n",
    "        tmp_asset = df_asset[(df_asset[\"REPORT\"] == report) & (df_asset[\"PLATFORM\"] == platform) & (df_asset[\"OWNER\"] == owner)].reset_index(drop=True)\n",
    "        if len(tmp_asset) > 0:\n",
    "            if image_link:\n",
    "                image_link = tmp_asset.loc[0 , \"IMAGE_LINK\"]\n",
    "            if html_link:\n",
    "                html_link = tmp_asset.loc[0 , \"HTML_LINK\"]\n",
    "            if csv_link:\n",
    "                csv_link = tmp_asset.loc[0 , \"CSV_LINK\"]\n",
    "\n",
    "    # Save assets\n",
    "    df_new = pd.DataFrame([new_asset])\n",
    "    df_new = df_new.sort_values(by=\"DATE_EXTRACT\").reset_index(drop=True)\n",
    "    df_asset = pd.concat([df_asset, df_new]).drop_duplicates([\"REPORT\", \"PLATFORM\", \"OWNER\"], keep=\"last\").reset_index(drop=True)\n",
    "    save_data(df_asset, ASSETS)\n",
    "    \n",
    "    # Manage page icon\n",
    "    page_icon = get_logo(platform, page_icon)\n",
    "    \n",
    "    # Decode database id\n",
    "    database_id = naas.secret.get(name=\"NOTION_DATABASE_URL\").split(\"/\")[-1].split(\"?v=\")[0]\n",
    "    \n",
    "    # Get pages from notion database\n",
    "    pages = notion.connect(NOTION_TOKEN).database.query(database_id)\n",
    "    \n",
    "    # Create or update page\n",
    "    page_new = True\n",
    "    for page in pages:\n",
    "        page_temp = page.df()\n",
    "        page_id = page_temp.loc[page_temp.Name == \"Report name\", \"Value\"].values\n",
    "        page_id2 = page_temp.loc[page_temp.Name == \"Platform\", \"Value\"].values\n",
    "        page_id3 = page_temp.loc[page_temp.Name == \"Owner\", \"Value\"].values\n",
    "        if page_id == report and page_id2 == platform and page_id3 == owner:\n",
    "            page_new = False\n",
    "            break\n",
    "    try:\n",
    "        if page_new:\n",
    "            page = notion.connect(NOTION_TOKEN).Page.new(database_id=database_id).create()\n",
    "            page.title(\"Report name\", report)\n",
    "            page.multi_select(\"Platform\", [platform])\n",
    "            page.select(\"Owner\", owner)\n",
    "            notion.client.pages.update(page_id=page.id, icon={'type': 'external', 'external': {'url': page_icon}})\n",
    "\n",
    "        # Check if image already exists\n",
    "        blocks = page.get_blocks()\n",
    "        for block in blocks:\n",
    "            content_block = getattr(block, block.type)\n",
    "            if block.type == \"image\":\n",
    "                image_url = block.image.external.url\n",
    "                if image_url.startswith(\"https://public.naas.ai/\"):\n",
    "                    notion.connect(NOTION_TOKEN).blocks.delete(block.id)\n",
    "            if block.type == \"paragraph\":\n",
    "                if len(block.paragraph.text) > 0:\n",
    "                    text = block.paragraph.text[0].text.content\n",
    "                    if text == \"Open dynamic chart\":\n",
    "                        notion.connect(NOTION_TOKEN).blocks.delete(block.id)\n",
    "                    if text == \"Download CSV\":\n",
    "                        notion.connect(NOTION_TOKEN).blocks.delete(block.id)\n",
    "        if image_link:\n",
    "            page.image(image_link)\n",
    "        if html_link:\n",
    "            res = page.paragraph(\"Open dynamic chart\")\n",
    "            res.paragraph.text[0].href = html_link\n",
    "            res.paragraph.text[0].text.link = Link(html_link)\n",
    "            res = page.rich_text(\"Chart\", \"Open dynamic chart\")\n",
    "            res.rich_text[0].href = html_link\n",
    "            res.rich_text[0].text.link = Link(html_link)\n",
    "        if csv_link:\n",
    "            res = page.paragraph(\"Download CSV\")\n",
    "            res.paragraph.text[0].href = csv_link\n",
    "            res.paragraph.text[0].text.link = Link(csv_link)\n",
    "                \n",
    "        # Update value\n",
    "        value, value_comp, varv, varp = calc_value(df)\n",
    "        not_stats = [\"Frequency\",\n",
    "                     \"Views reach\",\n",
    "                     \"World cloud\",\n",
    "                     \"Top posts\",\n",
    "                     \"Top fans\",\n",
    "                     \"New fans\"]\n",
    "        if report not in not_stats and platform != YOUTUBE:\n",
    "            page.number(\"This month\", float(value))\n",
    "            page.number(\"Last month\", float(value_comp))\n",
    "            page.number(\"Variation\", float(varv))\n",
    "            page.number(\"Variation %\", round(float(varp), 4))\n",
    "            if varv > 0:\n",
    "                sentiment = f\"ðŸŸ¢Â +{str(varv)} (+{str(round(varp * 100, 1))}%)\"\n",
    "            elif varv < 0:\n",
    "                sentiment = f\"ðŸ”´Â {str(varv)} ({str(round(varp * 100, 1))}%)\"\n",
    "            elif varv == 0:\n",
    "                sentiment = \"ðŸŸ \"\n",
    "            page.rich_text(\"Sentiment\", sentiment)\n",
    "        page.date(\"Last updated date\", datetime.now(pytz.timezone(TIMEZONE)).strftime(\"%Y-%m-%d %H:%M:%S%z\"))\n",
    "\n",
    "        # Create page in Notion\n",
    "        page.update()\n",
    "        print(f\"âœ… Page '{report} - {platform} - {owner}' updated in Notion.\")\n",
    "    except Exception as e:\n",
    "        raise(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6749e5ef-5883-4d50-be36-86268bf5e2a5",
   "metadata": {},
   "source": [
    "### List new connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfc46e8-f831-403e-a114-58c017691dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_new_connections(report,\n",
    "                         platform,\n",
    "                         owner,\n",
    "                         df=pd.DataFrame(),\n",
    "                         image_link=None,\n",
    "                         html_link=None,\n",
    "                         csv_link=None,\n",
    "                         page_icon=None,\n",
    "                         ):\n",
    "    # Date now number\n",
    "    date_now_number = int(datetime.now().strftime(\"%Y%m%d\"))\n",
    "    \n",
    "    # Manage page icon\n",
    "    page_icon = get_logo(platform, page_icon)\n",
    "    \n",
    "    # Decode database id\n",
    "    database_id = naas.secret.get(name=\"NOTION_DATABASE_URL\").split(\"/\")[-1].split(\"?v=\")[0]\n",
    "    \n",
    "    # Get pages from notion database\n",
    "    pages = notion.connect(NOTION_TOKEN).database.query(database_id)\n",
    "    \n",
    "    # Create or update page\n",
    "    page_new = True\n",
    "    for page in pages:\n",
    "        page_temp = page.df()\n",
    "        page_id = page_temp.loc[page_temp.Name == \"Report name\", \"Value\"].values\n",
    "        page_id2 = page_temp.loc[page_temp.Name == \"Platform\", \"Value\"].values\n",
    "        page_id3 = page_temp.loc[page_temp.Name == \"Owner\", \"Value\"].values\n",
    "        if page_id == report and page_id2 == platform and page_id3 == owner:\n",
    "            page_new = False\n",
    "            break\n",
    "    try:\n",
    "        if page_new:\n",
    "            page = notion.connect(NOTION_TOKEN).Page.new(database_id=database_id).create()\n",
    "            page.title(\"Report name\", report)\n",
    "            page.multi_select(\"Platform\", [platform])\n",
    "            page.select(\"Owner\", owner)\n",
    "            notion.client.pages.update(page_id=page.id, icon={'type': 'external', 'external': {'url': page_icon}})\n",
    "            \n",
    "        # Delete page blocks\n",
    "        page = delete_page_blocks(page)\n",
    "#         blocks = page.get_blocks()\n",
    "#         stop_delete = False\n",
    "#         if len(blocks) > 0:\n",
    "#             while True:\n",
    "#                 for block in blocks:\n",
    "#                     if block.type == \"heading_3\":\n",
    "#                         text = block.heading_3.text\n",
    "#                         if len(text) > 0:\n",
    "#                             date = text[0].text.content\n",
    "#                             date_number = datetime.strptime(date, \"%Y-%m-%d\").strftime(\"%Y%m%d\")\n",
    "#                             if int(date_number) < date_now_number:\n",
    "#                                 stop_delete = True\n",
    "#                                 break\n",
    "#                     notion.connect(NOTION_TOKEN).blocks.delete(block.id)\n",
    "#                 blocks = page.get_blocks()\n",
    "#                 if len(blocks) == 0 or stop_delete:\n",
    "#                     break\n",
    "#         page.update()\n",
    "        dates = df.DATE.unique()\n",
    "        for d in dates:\n",
    "#             tmp_df = df[(df.DATE == d) & (df.DATE_NUMBER.astype(int) > date_now_number)].reset_index(drop=True)\n",
    "            tmp_df = df[(df.DATE == d)].reset_index(drop=True)\n",
    "            if len(tmp_df) > 0:\n",
    "                page.heading_3(d)\n",
    "                for index, row in tmp_df.iterrows():\n",
    "                    res = page.bulleted_list_item(f\"{row.FIRSTNAME} {row.LASTNAME} - {row.OCCUPATION}\")\n",
    "                    res.bulleted_list_item.text[0].href = row.PROFILE_URL\n",
    "                    res.bulleted_list_item.text[0].text.link = Link(row.PROFILE_URL)\n",
    "\n",
    "        # Create page in Notion\n",
    "        value, value_comp, varv, varp = calc_value(csv_input)\n",
    "        page.number(\"This month\", float(value))\n",
    "        page.number(\"Last month\", float(value_comp))\n",
    "        page.number(\"Variation\", float(varv))\n",
    "        page.number(\"Variation %\", round(float(varp), 4))\n",
    "        if varv > 0:\n",
    "            sentiment = f\"ðŸŸ¢Â +{str(int(varv))} (+{str(round(varp * 100, 1))}%)\"\n",
    "        elif varv < 0:\n",
    "            sentiment = f\"ðŸ”´Â {str(int(varv))} ({str(round(varp * 100, 1))}%)\"\n",
    "        elif varv == 0:\n",
    "            sentiment = \"ðŸŸ \"\n",
    "        page.rich_text(\"Sentiment\", sentiment)\n",
    "        page.date(\"Last updated date\", datetime.now(pytz.timezone(TIMEZONE)).strftime(\"%Y-%m-%d %H:%M:%S%z\"))\n",
    "        page.update()\n",
    "        print(f\"âœ… Page '{report} - {platform} - {owner}' updated in Notion.\")\n",
    "    except Exception as e:\n",
    "        raise(e)\n",
    "    return page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b3ae26-1bd4-49c7-a357-fabbfb13a253",
   "metadata": {},
   "source": [
    "### List top posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1ec6c7-8338-4550-8664-e0382221bafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_top_posts(report,\n",
    "                   platform,\n",
    "                   owner,\n",
    "                   df=pd.DataFrame(),\n",
    "                   image_link=None,\n",
    "                   html_link=None,\n",
    "                   csv_link=None,\n",
    "                   page_icon=None,\n",
    "                  ):\n",
    "    # Manage page icon\n",
    "    page_icon = get_logo(platform, page_icon)\n",
    "    \n",
    "    # Decode database id\n",
    "    database_id = naas.secret.get(name=\"NOTION_DATABASE_URL\").split(\"/\")[-1].split(\"?v=\")[0]\n",
    "    \n",
    "    # Get pages from notion database\n",
    "    pages = notion.connect(NOTION_TOKEN).database.query(database_id)\n",
    "    \n",
    "    # Create or update page\n",
    "    page_new = True\n",
    "    for page in pages:\n",
    "        page_temp = page.df()\n",
    "        page_id = page_temp.loc[page_temp.Name == \"Report name\", \"Value\"].values\n",
    "        page_id2 = page_temp.loc[page_temp.Name == \"Platform\", \"Value\"].values\n",
    "        page_id3 = page_temp.loc[page_temp.Name == \"Owner\", \"Value\"].values\n",
    "        if page_id == report and page_id2 == platform and page_id3 == owner:\n",
    "            page_new = False\n",
    "            break\n",
    "    try:\n",
    "        if page_new:\n",
    "            page = notion.connect(NOTION_TOKEN).Page.new(database_id=database_id).create()\n",
    "            page.title(\"Report name\", report)\n",
    "            page.multi_select(\"Platform\", [platform])\n",
    "            page.select(\"Owner\", owner)\n",
    "            notion.client.pages.update(page_id=page.id, icon={'type': 'external', 'external': {'url': page_icon}})\n",
    "            \n",
    "        # Delete page blocks\n",
    "        page = delete_page_blocks(page)\n",
    "        \n",
    "        kpis = [\"ENGAGEMENT_SCORE\", \"VIEWS\", \"COMMENTS\", \"LIKES\"]\n",
    "        for kpi in kpis:\n",
    "            heading_3 = f\"By {kpi.lower()}\"\n",
    "            if kpi == \"ENGAGEMENT_SCORE\":\n",
    "                heading_3 = \"By engagement rate\"\n",
    "            page.heading_3(heading_3)\n",
    "            tmp_df = df.sort_values(by=kpi, ascending=False).reset_index(drop=True)[:3]\n",
    "            for index, row in tmp_df.iterrows():\n",
    "                value = row[kpi]\n",
    "                kpi_d = kpi.lower()\n",
    "                title = f\"{row.TITLE} ({value} {kpi_d})\"\n",
    "                if kpi == \"ENGAGEMENT_SCORE\":\n",
    "                    value = \"{:,.2%}\".format(value)\n",
    "                    title = f\"{row.TITLE} ({value})\"\n",
    "                res = page.numbered_list_item(title)\n",
    "                res.numbered_list_item.text[0].href = row.POST_URL\n",
    "                res.numbered_list_item.text[0].text.link = Link(row.POST_URL)\n",
    "            \n",
    "        # Create page in Notion\n",
    "        page.date(\"Last updated date\", datetime.now(pytz.timezone(TIMEZONE)).strftime(\"%Y-%m-%d %H:%M:%S%z\"))\n",
    "        page.update()\n",
    "        print(f\"âœ… Page '{report} - {platform} - {owner}' updated in Notion.\")\n",
    "    except Exception as e:\n",
    "        raise(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1cee58-9618-45c3-a31e-02a822bed0ef",
   "metadata": {},
   "source": [
    "### List top fans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff60fe5-499e-49cc-af6e-375db26070f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_top_fans(report,\n",
    "                  platform,\n",
    "                  owner,\n",
    "                  df=pd.DataFrame(),\n",
    "                  image_link=None,\n",
    "                  html_link=None,\n",
    "                  csv_link=None,\n",
    "                  page_icon=None,\n",
    "                  ):\n",
    "    # Manage dataframe empty\n",
    "    if len(df) == 0:\n",
    "        print(f\"ðŸ›‘ Nothing to update in Notion.\")\n",
    "        return\n",
    "    else:\n",
    "        df = df[:NO_TOP_FANS]\n",
    "    \n",
    "    # Manage page icon\n",
    "    page_icon = get_logo(platform, page_icon)\n",
    "    \n",
    "    # Decode database id\n",
    "    database_id = naas.secret.get(name=\"NOTION_DATABASE_URL\").split(\"/\")[-1].split(\"?v=\")[0]\n",
    "    \n",
    "    # Get pages from notion database\n",
    "    pages = notion.connect(NOTION_TOKEN).database.query(database_id)\n",
    "    \n",
    "    # Create or update page\n",
    "    page_new = True\n",
    "    for page in pages:\n",
    "        page_temp = page.df()\n",
    "        page_id = page_temp.loc[page_temp.Name == \"Report name\", \"Value\"].values\n",
    "        page_id2 = page_temp.loc[page_temp.Name == \"Platform\", \"Value\"].values\n",
    "        page_id3 = page_temp.loc[page_temp.Name == \"Owner\", \"Value\"].values\n",
    "        if page_id == report and page_id2 == platform and page_id3 == owner:\n",
    "            page_new = False\n",
    "            break\n",
    "    try:\n",
    "        if page_new:\n",
    "            page = notion.connect(NOTION_TOKEN).Page.new(database_id=database_id).create()\n",
    "            page.title(\"Report name\", report)\n",
    "            page.multi_select(\"Platform\", [platform])\n",
    "            page.select(\"Owner\", owner)\n",
    "            notion.client.pages.update(page_id=page.id, icon={'type': 'external', 'external': {'url': page_icon}})\n",
    "            \n",
    "        # Delete page blocks\n",
    "        page = delete_page_blocks(page)\n",
    "        \n",
    "        page.heading_3(\"Ranking this month\")\n",
    "        for index, row in df.iterrows():\n",
    "            text = f\"{row.FULLNAME} - {row.OCCUPATION} ({str(row.PROFILE_ID)})\"\n",
    "            res = page.numbered_list_item(text)\n",
    "            res.numbered_list_item.text[0].href = row.PROFILE_URL\n",
    "            res.numbered_list_item.text[0].text.link = Link(row.PROFILE_URL)\n",
    "\n",
    "        # Create page in Notion\n",
    "        page.date(\"Last updated date\", datetime.now(pytz.timezone(TIMEZONE)).strftime(\"%Y-%m-%d %H:%M:%S%z\"))\n",
    "        page.update()\n",
    "        print(f\"âœ… Page '{report} - {platform} - {owner}' updated in Notion.\")\n",
    "    except Exception as e:\n",
    "        raise(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3415f3-3310-4f7f-8015-5f27e15dbda4",
   "metadata": {},
   "source": [
    "### List new fans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df00df3-7000-4a20-afa8-884d8ff5e033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_new_fans(report,\n",
    "                  platform,\n",
    "                  owner,\n",
    "                  df_engagements,\n",
    "                  df,\n",
    "                  page_icon=None,\n",
    "                  ):\n",
    "    # Manage dataframe empty\n",
    "    if len(df_engagements) == 0:\n",
    "        print(f\"ðŸ›‘ Nothing to update in Notion.\")\n",
    "        return\n",
    "    \n",
    "    # Manage page icon\n",
    "    page_icon = get_logo(platform, page_icon)\n",
    "    \n",
    "    # Decode database id\n",
    "    database_id = naas.secret.get(name=\"NOTION_DATABASE_URL\").split(\"/\")[-1].split(\"?v=\")[0]\n",
    "    \n",
    "    # Get pages from notion database\n",
    "    pages = notion.connect(NOTION_TOKEN).database.query(database_id)\n",
    "    \n",
    "    # Create or update page\n",
    "    page_new = True\n",
    "    for page in pages:\n",
    "        page_temp = page.df()\n",
    "        page_id = page_temp.loc[page_temp.Name == \"Report name\", \"Value\"].values\n",
    "        page_id2 = page_temp.loc[page_temp.Name == \"Platform\", \"Value\"].values\n",
    "        page_id3 = page_temp.loc[page_temp.Name == \"Owner\", \"Value\"].values\n",
    "        if page_id == report and page_id2 == platform and page_id3 == owner:\n",
    "            page_new = False\n",
    "            break\n",
    "    try:\n",
    "        if page_new:\n",
    "            page = notion.connect(NOTION_TOKEN).Page.new(database_id=database_id).create()\n",
    "            page.title(\"Report name\", report)\n",
    "            page.multi_select(\"Platform\", [platform])\n",
    "            page.select(\"Owner\", owner)\n",
    "            notion.client.pages.update(page_id=page.id, icon={'type': 'external', 'external': {'url': page_icon}})\n",
    "            \n",
    "        # Create posts dataframe\n",
    "        df_posts = df_engagements[[\"TITLE\", \"POST_URL\", \"PUBLISHED_DATE\"]].drop_duplicates([\"POST_URL\"]).reset_index(drop=True)\n",
    "        df_posts[\"SCENARIO\"] = pd.to_datetime(df_posts[\"PUBLISHED_DATE\"].str[:-6]).dt.strftime(PERIOD)\n",
    "        df_posts = df_posts[(df_posts[\"SCENARIO\"] == datetime.now().strftime(PERIOD))][:LINKEDIN_POSTS_UPDATE].reset_index(drop=True)\n",
    "        \n",
    "        # Delete page blocks\n",
    "        page = delete_page_blocks(page)\n",
    "#         stop_delete = False\n",
    "#         if len(blocks) > 0:\n",
    "#             from datetime import timedelta\n",
    "#             df_posts[\"PUBLISHED_DATE\"] = pd.to_datetime(df_posts[\"PUBLISHED_DATE\"].str[:-6])\n",
    "#             df_posts = df_posts[df_posts[\"PUBLISHED_DATE\"] > (datetime.now() - timedelta(days=7))]\n",
    "#             titles = df_posts[\"TITLE\"].unique()\n",
    "#             while True:\n",
    "#                 for block in blocks:\n",
    "#                     if block.type == \"heading_3\":\n",
    "#                         text = block.heading_3.text\n",
    "#                         if len(text) > 0:\n",
    "#                             title = text[0].text.content\n",
    "#                             if title not in titles:\n",
    "#                                 stop_delete = True\n",
    "#                                 break\n",
    "#                     notion.connect(NOTION_TOKEN).blocks.delete(block.id)\n",
    "#                 blocks = page.get_blocks()\n",
    "#                 if len(blocks) == 0 or stop_delete:\n",
    "#                     break\n",
    "#             page.update()\n",
    "    \n",
    "        # Add new fans by posts\n",
    "        for index, row in df_posts.iterrows():\n",
    "            # Add posts\n",
    "            res = page.heading_3(row.TITLE)\n",
    "            res.heading_3.text[0].href = row.POST_URL\n",
    "            res.heading_3.text[0].text.link = Link(row.POST_URL)\n",
    "            \n",
    "            # Add new\n",
    "            tmp_df = df[df.POST_URL == row.POST_URL].reset_index(drop=True)\n",
    "            def add_reactions(df, reaction):\n",
    "                df = df[df.REACTION == reaction]\n",
    "                if reaction == \"LIKES\":\n",
    "                    page.paragraph(f\"New profile who liked ({len(df)}):\")\n",
    "                elif reaction == \"COMMENTS\":\n",
    "                    page.paragraph(f\"New profile who commented ({len(df)}):\")\n",
    "                for index, row in df.iterrows():\n",
    "                    text = f\"{row.FULLNAME} - {row.OCCUPATION}\"\n",
    "                    res = page.bulleted_list_item(text)\n",
    "                    res.bulleted_list_item.text[0].href = row.PROFILE_URL\n",
    "                    res.bulleted_list_item.text[0].text.link = Link(row.PROFILE_URL)\n",
    "                page.paragraph(\"\")\n",
    "            add_reactions(tmp_df, \"COMMENTS\")\n",
    "            add_reactions(tmp_df, \"LIKES\")\n",
    "\n",
    "\n",
    "        # Create page in Notion\n",
    "        page.date(\"Last updated date\", datetime.now(pytz.timezone(TIMEZONE)).strftime(\"%Y-%m-%d %H:%M:%S%z\"))\n",
    "        page.update()\n",
    "        print(f\"âœ… Page '{report} - {platform} - {owner}' updated in Notion.\")\n",
    "    except Exception as e:\n",
    "        raise(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a04761-1cac-4b46-a2f4-c2ec55c62a4d",
   "metadata": {},
   "source": [
    "### Update Notion Content DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61627cb-b0f7-4f11-ba30-2e04d0f66d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dynamic_properties(page, row):\n",
    "    # Page properties : dynamic\n",
    "    page.number(\"Engagment score\", round(float(row.ENGAGEMENT_SCORE), 4))\n",
    "    page.number(\"Views\", int(row.VIEWS))\n",
    "    page.number(\"Likes\", int(row.LIKES))\n",
    "    page.number(\"Comments\", int(row.COMMENTS))\n",
    "    page.number(\"Shares\", int(row.SHARES))\n",
    "    return page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d80146-4f94-4905-bb4a-6fdc0e8de637",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_content_notion(df, database_url):\n",
    "    # Decode database id\n",
    "    database_id = database_url.split(\"/\")[-1].split(\"?v=\")[0]\n",
    "    \n",
    "    # Get pages from notion database\n",
    "    pages = notion.connect(NOTION_TOKEN).database.query(database_id, query={})\n",
    "    \n",
    "    # Manage dataframe empty\n",
    "    if len(df) == 0:\n",
    "        print(f\"ðŸ›‘ Nothing to update in Notion.\")\n",
    "        return\n",
    "    \n",
    "    # Loop in data\n",
    "    fillna = {\n",
    "        \"AUTHOR_URL\": \"\",\n",
    "        \"TITLE\": \"\",\n",
    "        \"TEXT\": \"\",\n",
    "        \"COMPANY_MENTION\": \"\",\n",
    "        \"PROFILE_MENTION\": \"\",\n",
    "        \"TAGS\": \"\",\n",
    "        \"TAGS_COUNT\": 0,\n",
    "        \"LINKS\": \"\",\n",
    "        \"LINKS_COUNT\": 0,\n",
    "        \"EMOJIS\": \"\",\n",
    "        \"EMOJIS_COUNT\": 0,\n",
    "        \"CONTENT_TITLE\": \"\",\n",
    "        \"CONTENT_URL\": \"\",\n",
    "        \"CONTENT_ID\": \"\",\n",
    "        \"POLL_ID\": \"\",\n",
    "        \"POLL_QUESTION\": \"\",\n",
    "        \"POLL_RESULTS\": \"\",\n",
    "        \"IMAGE_URL\": \"\"\n",
    "    }\n",
    "    df = df.fillna(fillna)\n",
    "    for i, row in df.iterrows():\n",
    "        title = row.TITLE\n",
    "        content_title = row.CONTENT_TITLE\n",
    "        if title is None and content_title is not None:\n",
    "            title = f\"Repost - {content_title}\"\n",
    "        elif title is None and content_title is None:\n",
    "            title = \"Repost\"\n",
    "        post_url = row.POST_URL\n",
    "        print(post_url)\n",
    "        \n",
    "        # Create or update page\n",
    "        page_new = True\n",
    "        for page in pages:\n",
    "            page_temp = page.df()\n",
    "            page_id = page_temp.loc[page_temp.Name == \"Content URL\", \"Value\"].values\n",
    "            if page_id == post_url:\n",
    "                page_new = False\n",
    "                break\n",
    "        try:\n",
    "            if page_new:\n",
    "                # Create new page in notion\n",
    "                page = notion.Page.new(database_id=database_id).create()\n",
    "\n",
    "                # Page properties : static\n",
    "                page.date(\"Publication Date\", row.PUBLISHED_DATE)\n",
    "                page.title(\"Name\", title)\n",
    "                page.select(\"Content type\", row.CONTENT)\n",
    "                page.select(\"Platform\", \"LinkedIn\")\n",
    "                page.select(\"Status\", \"Published âœ¨\")\n",
    "                page.select(\"Author\", row.AUTHOR_NAME)\n",
    "                profile_mention = row.PROFILE_MENTION\n",
    "                if profile_mention is not None:\n",
    "                    if len(profile_mention) > 2:\n",
    "                        page.rich_text(\"Profile mention\", profile_mention)\n",
    "                company_mention = row.COMPANY_MENTION\n",
    "                if company_mention is not None:\n",
    "                    if len(company_mention) > 2:\n",
    "                        page.rich_text(\"Company mention\", company_mention)\n",
    "                page.number(\"Nb tags\", int(row.TAGS_COUNT))\n",
    "                tags = row.TAGS\n",
    "                if tags is None:\n",
    "                    tags = \"\"\n",
    "                else:\n",
    "                    if len(tags) < 2:\n",
    "                        tags = \"\"\n",
    "                page.rich_text(\"Tags\", tags)\n",
    "                page.number(\"Nb emojis\", int(row.EMOJIS_COUNT))\n",
    "                emojis = row.EMOJIS\n",
    "                if emojis is None:\n",
    "                    emojis = \"\"\n",
    "                else:\n",
    "                    if len(emojis) < 2:\n",
    "                        emojis = \"\"\n",
    "                page.rich_text(\"Emojis\", emojis)\n",
    "                page.number(\"Nb links\", int(row.LINKS_COUNT))\n",
    "                links = row.LINKS\n",
    "                if links is not None:\n",
    "                    if len(links) > 2:\n",
    "                        page.link(\"Links\", links)\n",
    "                page.number(\"Nb characters\", int(row.CHARACTER_COUNT))\n",
    "                page.link(\"Content URL\", post_url)\n",
    "                \n",
    "                # Page blocks text\n",
    "                page.heading_1(\"Text\")\n",
    "                text = row.TEXT\n",
    "                if text is not None:\n",
    "                    split_text = text.split(\"\\n\")\n",
    "                    for t in split_text:\n",
    "                        page.paragraph(t)\n",
    "                    \n",
    "                # Page blocks content\n",
    "                image_url = row.IMAGE_URL\n",
    "                content_url = row.CONTENT_URL\n",
    "                poll_question = row.POLL_QUESTION\n",
    "                if image_url or content_title or content_url or poll_question:\n",
    "                    page.heading_1(\"Content\")\n",
    "                \n",
    "                # Add image in content section\n",
    "                if image_url:\n",
    "                    page.heading_2(\"Image\")\n",
    "                    page.paragraph(image_url)\n",
    "                    \n",
    "                # Add post in content section\n",
    "                if content_title:\n",
    "                    page.heading_2(\"Media\")\n",
    "                    page.heading_3(content_title)\n",
    "                \n",
    "                if content_url:\n",
    "                    page.paragraph(content_url)\n",
    "                \n",
    "                # Add poll graph in content section\n",
    "                if poll_question:\n",
    "                    page.heading_3(\"Poll\")\n",
    "                    page.paragraph(row.POLL_RESULTS)\n",
    "                \n",
    "                # Page properties : dynamic\n",
    "                page = update_dynamic_properties(page, row)\n",
    "                \n",
    "                # Create page in Notion\n",
    "                page.update()\n",
    "                print(f\"âœ… Page '{title}' created in Notion.\", '\\n')\n",
    "            else:\n",
    "                # Page properties : dynamic\n",
    "                page = update_dynamic_properties(page, row)\n",
    "                \n",
    "                # Update page\n",
    "                page.update()\n",
    "                print(f\"ðŸ“ˆ Post stats updated in notion for page '{title}'.\", '\\n')\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error creating page '{title}' in Notion\", e)\n",
    "            print(row)\n",
    "            raise(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
